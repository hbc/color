#!/usr/bin/env python
"""Check concordance of a new set of calls against pre-calculated replicate calls.

Uses ensemble calls generated by identify_inconsistent.py as a baseline,
performing evaluation again then and reporting TP, FP and FNs.

Usage:
  check_concordance.py <config file> <replicate work dir> <all files to process>
"""
import csv
import gzip
import os
import sys
import re

import toolz as tz
import yaml

from bcbio import utils
from bcbio.distributed.transaction import file_transaction
from bcbio.provenance import do
from bcbio.variation import vcfutils

def main(config_file, replicate_dir, *to_process):
    with open(config_file) as in_handle:
        config = yaml.load(in_handle)
    config["dirs"] = {"work": os.getcwd(), "replicate": replicate_dir}
    header = [["sample"], ["concordant", "snp"], ["concordant", "indel"],
              ["discordant", "snp", "extra"], ["discordant", "snp", "missing"],
              ["discordant", "indel", "extra"], ["discordant", "indel", "missing"]]
    out_file = "replicate-summary.csv"
    with open(out_file, "w") as out_handle:
        writer = csv.writer(out_handle)
        writer.writerow(["_".join(xs) for xs in header])
        for cur_vcf in to_process:
            stats = calc_concordance(cur_vcf, config)
            writer.writerow([tz.get_in(xs, stats) for xs in header])

def calc_concordance(orig_vcf_file, config):
    pat = re.compile(tz.get_in(["inputs", "coriellre"], config))
    name = pat.search(os.path.basename(orig_vcf_file)).group(0)
    orig_file = _convert_to_bgzipped(orig_vcf_file, name, tz.get_in(["dirs", "work"], config))
    ann_file = _annotate_repeats(orig_file, config["annotations"],
                                 tz.get_in(["resources", "ref_file"], config))
    filter_file = _add_filters(ann_file, config)
    return _compare_to_rm(filter_file, name, config)

def _compare_to_rm(in_file, name, config):
    """Compare to pre-calculated reference materials, returning concordance.
    """
    bed_file = os.path.join(tz.get_in(["dirs", "replicate"], config),
                            "bedprep", "%s-gatkclean.bed" % utils.splitext_plus(
                                os.path.basename(tz.get_in(["inputs", "regions"], config)))[0])
    cmp_file = os.path.join(tz.get_in(["dirs", "replicate"], config),
                            "compare", name, "%s-ensemble-ready.vcf.gz" % name)
    out_file = os.path.join(os.getcwd(), "%s-evalwork" % utils.splitext_plus(os.path.basename(in_file))[0],
                            "work", "eval-config-grading.yaml")
    if not utils.file_exists(out_file):
        cmd = ["java", "-jar", tz.get_in(["resources", "bcbio_variation"], config),
               "variant-utils", "comparetwo", in_file, cmp_file, tz.get_in(["resources", "ref_file"], config),
               bed_file]
        do.run(cmd, "bcbio.variation comparison")
    with open(out_file) as in_handle:
        stats = yaml.load(in_handle)[0]
    for vtype in ["snp", "indel"]:
        for ctype in ["extra", "missing"]:
            if vtype not in stats["discordant"]:
                stats["discordant"][vtype] = {}
            vals = stats["discordant"][vtype].get(ctype, {"none": 0})
            stats["discordant"][vtype][ctype] = sum(vals.values())
    stats["concordant"] = stats["concordant"]["concordant"]
    return stats

def _convert_to_bgzipped(in_file, name, work_dir):

    out_file = os.path.join(utils.safe_makedir(os.path.join(work_dir, name)),
                            "%s.vcf.gz" % name)
    if not utils.file_exists(out_file):
        with file_transaction({}, out_file) as tx_out_file:
            cmd = r"gunzip -c {in_file} | sed 's/FORMAT\t.*$/FORMAT\t{name}/' | bgzip -c > {tx_out_file}"
            do.run(cmd.format(**locals()), "Fix VCF")
    vcfutils.bgzip_and_index(out_file, {})
    return out_file

def _add_filters(in_file, config):
    cur_file = in_file
    for ftype, fname in config["filters"]:
        cur_file, _ = _filter_vcf(cur_file, ftype, fname)
    return cur_file

# ## Reused

def _annotate_repeats(vcf_file, annotations, ref_file):
    """Associate variants with repeat tracks.
    """
    header = '##INFO=<ID=RPT,Number=.,Type=String,Description="Repeat track overlaps">'
    out_file = "%s-repeats%s" % utils.splitext_plus(vcf_file)
    if not utils.file_exists(out_file):
        with file_transaction({}, out_file) as tx_out_file:
            header_file = "%s-repeatheader.txt" % utils.splitext_plus(tx_out_file)[0]
            with open(header_file, "w") as out_handle:
                out_handle.write(header)
            prep_bed = _prep_annotations(annotations, ref_file)
            cmd = ("bcftools annotate -a {prep_bed} -c CHROM,FROM,TO,RPT "
                   "-h {header_file} {vcf_file} -O z -o {tx_out_file}")
            do.run(cmd.format(**locals()), "Annotate input variants with repeats")
    vcfutils.bgzip_and_index(out_file, {})
    return out_file

def _prep_annotations(annotations, ref_file):
    """Convert annotation file to have standard name, and merge into single file.
    """
    all_anns = []
    slops = {"rmsk": 0, "lcr": 20}
    for name, orig_bed in annotations.items():
        cur_out_file = "%s-bcftoolsprep.bed" % (utils.splitext_plus(orig_bed)[0])
        if not utils.file_exists(cur_out_file):
            with file_transaction({}, cur_out_file) as tx_out_file:
                cur_slop = slops[name]
                if cur_slop:
                    slop_cmd = "bedtools slop -b {cur_slop} -g {ref_file}.fai -i - | "
                else:
                    slop_cmd = ""
                cmd = ("gunzip -c {orig_bed} | " +
                       slop_cmd +
                       """awk '{{ $4 = "{name}" }}; {{print}}' FS='\\t' OFS='\\t' """
                       "> {tx_out_file}")
                do.run(cmd.format(**locals()), "Prepare annotation file for bcftools")
        all_anns.append(cur_out_file)
    out_file = "%s-merged.bed.gz" % (utils.splitext_plus(all_anns[0])[0])
    if not utils.file_exists(out_file):
        with file_transaction({}, out_file) as tx_out_file:
            bed_files_str = " ".join(all_anns)
            cmd = ("cat {bed_files_str} | sort -k1,1 -k2,2n | "
                   "bedtools merge -d 1 -c 4 -o distinct -i - | bgzip -c > {tx_out_file}")
            do.run(cmd.format(**locals()), "Merge all input annotations")
    if not utils.file_exists(out_file + ".tbi"):
        cmd = "tabix -p bed {out_file}"
        do.run(cmd.format(**locals()), "tabix index prepped annotation file")
    return out_file

def _filter_vcf(orig_file, ftype="max", name="ColorCustom"):
    """Filter VCF with bcftools, providing count summary of items removed.
    """
    exprs = {}
    # XXX No GC annotations without BAM files
    # exprs["max"] = ('SUM(AD[*]) < 15 || '
    #                 'PL[0] / SUM(AD[*]) <= 3.0 || '
    #                 'GC < 20.0 || GC > 77.0 || '
    #                 'RPT[*] = "rmsk" || '
    #                 'RPT[*] = "lcr"')
    exprs["max"] = ('SUM(AD[*]) < 15 || '
                    'PL[0] / SUM(AD[*]) <= 3.0 || '
                    'RPT[*] = "rmsk" || '
                    'RPT[*] = "lcr"')
    exprs["min2"] = ('SUM(AD[*]) < 15 || '
                     'PL[0] / SUM(AD[*]) <= 3.0 || '
                     'RPT[*] = "lcr"')
    exprs["min1"] = ('SUM(AD[*]) < 15 || '
                     'PL[0] / SUM(AD[*]) <= 3.0 || '
                     '(RPT[*] = "lcr" && RPT[*] = "rmsk")')
    exprs["min0"] = ('SUM(AD[*]) < 15 || '
                     'PL[0] / SUM(AD[*]) <= 3.0')
    exprs["all"] = 'GC < 1.0'
    expr = exprs[ftype]
    base, ext = utils.splitext_plus(orig_file)
    out_file = "%s-filter%s%s" % (base, ftype, ext)
    if not utils.file_exists(out_file):
        with file_transaction({}, out_file) as tx_out_file:
            cmd = ("bcftools filter -O z -o {tx_out_file} "
                   "-m '+' -e '{expr}' -s '{name}' {orig_file}")
            do.run(cmd.format(**locals()), "Hard filter VCF")
    vcfutils.bgzip_and_index(out_file, {})
    def count(f):
        with gzip.open(f) as h:
            return sum(1 for line in h if not line.startswith("#") and line.split("\t")[6] in  ["PASS", "."])
    removed_stats = {"orig": count(orig_file), "final": count(out_file)}
    removed_stats["pct"] = float(removed_stats["final"]) * 100.0 / removed_stats["orig"]
    return out_file, removed_stats

if __name__ == "__main__":
    main(*sys.argv[1:])
